# -*- coding: utf-8 -*-
"""Copy of data preprocessing

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/114NhldjxTcA41qmDZSsE3A0_nqldMMMF
"""

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd

dataset = pd.read_csv('waterQuality1.csv')
x = dataset.iloc[: , :-1].values
y = dataset.iloc[: , -1].values

print(x)

from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
x_train[:, 3:] = sc.fit_transform(x_train[:, 3:])
x_test[:, 3:] = sc.transform(x_test[:, 3:])

print(y)

print(x)

from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder
from sklearn.impute import SimpleImputer
import numpy as np
import pandas as pd

# Ensure all relevant columns are numeric, coercing errors to NaN
# Assuming the first column is the one causing issues and needs encoding,
# but converting all columns to numeric is a safer general approach
for col in dataset.columns[:-1]: # Exclude the target variable column
    dataset[col] = pd.to_numeric(dataset[col], errors='coerce')

# Separate features (x) and target (y) again after cleaning
x = dataset.iloc[:, :-1].values
y = dataset.iloc[:, -1].values


# Impute missing values in x
imputer = SimpleImputer(missing_values=np.nan, strategy='mean')
x_imputed = imputer.fit_transform(x)


# Apply OneHotEncoder to the first column and pass through the rest
# The first column was already identified as potentially requiring encoding based on previous attempts.
# Ensure the index [0] corresponds to the column needing one-hot encoding
ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [0])], remainder='passthrough')
x_encoded = ct.fit_transform(x_imputed)

# Convert the sparse matrix to dense if necessary (OneHotEncoder outputs sparse by default)
if hasattr(x_encoded, 'toarray'):
    x = x_encoded.toarray()
else:
    x = x_encoded # Already dense

print(x)

print(x)

print(y)

from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
y = le.fit_transform(y)

print(y)

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

# Split the data into training and testing sets
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=1)

# Apply feature scaling to all columns in the training and testing sets
sc = StandardScaler()
x_train = sc.fit_transform(x_train)
x_test = sc.transform(x_test)

print("x_train shape:", x_train.shape)
print("x_test shape:", x_test.shape)
print("y_train shape:", y_train.shape)
print("y_test shape:", y_test.shape)

from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.impute import SimpleImputer
import numpy as np
import pandas as pd

# Ensure all relevant columns are numeric, coercing errors to NaN
for col in x.columns:
    x[col] = pd.to_numeric(x[col], errors='coerce')

# Impute missing values
imputer = SimpleImputer(missing_values=np.nan, strategy='mean')
x_imputed = imputer.fit_transform(x)

# Apply OneHotEncoder to the first column and pass through the rest
# The first column was already identified as potentially requiring encoding based on previous attempts.
ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [0])], remainder='passthrough')
x_encoded = ct.fit_transform(x_imputed)

# Convert the sparse matrix to dense if necessary (OneHotEncoder outputs sparse by default)
if hasattr(x_encoded, 'toarray'):
    x_dense = x_encoded.toarray()
else:
    x_dense = x_encoded # Already dense

# Split the data
x_train, x_test, y_train, y_test = train_test_split(x_dense, y, test_size=0.2, random_state=1)

print("x_train shape:", x_train.shape)
print("x_test shape:", x_test.shape)
print("y_train shape:", y_train.shape)
print("y_test shape:", y_test.shape)

print(x_train)

print(x_test)

print(y_train)

print(y_test)

from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
x_train[:, 3:] = sc.fit_transform(x_train[:, 3:])
x_test[:, 3:] = sc.transform(x_test[:, 3:])

print(x_train)

print(x_test)